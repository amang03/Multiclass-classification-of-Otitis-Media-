import os
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications import EfficientNetB3, InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

# Set the directories for training data
train_dir = '/kaggle/input/om-testing-ds/New DS/Training dataset/Otitis Media'  
test_dir = ''

# Set parameters
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 8
EPOCHS = 100

# Data augmentation and preprocessing for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2  # Splitting 20% for validation
)

# Preprocessing for validation and test data (same as train without augmentation)
test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Also split 20% for test/validation

# Load training data and split into train/validation/test sets
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'  # 80% for training
)

val_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'  # 20% for validation
)

test_generator = test_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',  # Use the validation subset again for testing purposes
    shuffle=False
)

# Callback to stop training when no improvement
early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

# Function to build EfficientNetB3 model
def build_efficientnet_b3():
    base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
    for layer in base_model.layers[-50:]:
        layer.trainable = True

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Function to build InceptionV3 model
def build_inception_v3():
    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
    for layer in base_model.layers[-50:]:
        layer.trainable = True

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Function to evaluate and print metrics
def evaluate_and_print_metrics(model, test_generator):
    y_true = test_generator.classes  # True labels
    y_pred = np.argmax(model.predict(test_generator), axis=-1)  # Predicted labels

    # Calculate metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    # Specificity (True Negative Rate for each class)
    confusion = confusion_matrix(y_true, y_pred)
    TN = confusion.diagonal()
    specificity = np.mean(TN / np.sum(confusion, axis=1))

    print(f'Accuracy: {accuracy}')
    print(f'Precision: {precision}')
    print(f'Recall (Sensitivity): {recall}')
    print(f'F1-Score: {f1}')
    print(f'Specificity: {specificity}')

    print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

# Function to plot accuracy and loss curves
def plot_training_history(history, model_name):
    # Plot accuracy
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{model_name} Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{model_name} Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

# Training EfficientNetB3
model_efficientnet = build_efficientnet_b3()
model_checkpoint_efficientnet = ModelCheckpoint('best_efficientnet.keras', monitor='val_loss', save_best_only=True)
history_efficientnet = model_efficientnet.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=[early_stop, model_checkpoint_efficientnet]
)
model_efficientnet.save('efficientnet_b3_final_model.keras')
# Evaluate EfficientNetB3
evaluate_and_print_metrics(model_efficientnet, test_generator)

# Clear session to free memory
tf.keras.backend.clear_session()

# Training InceptionV3
model_inception = build_inception_v3()
model_checkpoint_inception = ModelCheckpoint('best_inception.keras', monitor='val_loss', save_best_only=True)
history_inception = model_inception.fit( # Assign the result to history_inception
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=[early_stop, model_checkpoint_inception]
)
model_inception.save('inception_v3_final_model.keras')
# Evaluate InceptionV3
evaluate_and_print_metrics(model_inception, test_generator)

plot_training_history(history_efficientnet, "EfficientNetB3")
plot_training_history(history_inception, "InceptionV3")
